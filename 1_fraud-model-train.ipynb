{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time    float64\n",
      "V1      float64\n",
      "V2      float64\n",
      "V3      float64\n",
      "V4      float64\n",
      "dtype: object\n",
      "Number of records: 284807\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "data_file='/Users/john/data-sets/creditcard.csv'\n",
    "data=pd.read_csv(data_file,header=0)\n",
    "print(data.dtypes.head())\n",
    "print('Number of records:',len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole data set: 284807\n",
      "Train and test set: 284315\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228513</th>\n",
       "      <td>145544.0</td>\n",
       "      <td>-0.643139</td>\n",
       "      <td>0.323888</td>\n",
       "      <td>-0.253890</td>\n",
       "      <td>-0.229861</td>\n",
       "      <td>-0.320347</td>\n",
       "      <td>-0.337035</td>\n",
       "      <td>0.016371</td>\n",
       "      <td>0.511599</td>\n",
       "      <td>0.664531</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.284546</td>\n",
       "      <td>0.264600</td>\n",
       "      <td>0.641559</td>\n",
       "      <td>0.167731</td>\n",
       "      <td>0.639755</td>\n",
       "      <td>-0.782464</td>\n",
       "      <td>0.447755</td>\n",
       "      <td>-0.108167</td>\n",
       "      <td>0.041705</td>\n",
       "      <td>100.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45271</th>\n",
       "      <td>42274.0</td>\n",
       "      <td>1.225032</td>\n",
       "      <td>0.309672</td>\n",
       "      <td>0.075764</td>\n",
       "      <td>1.172093</td>\n",
       "      <td>0.049135</td>\n",
       "      <td>-0.352607</td>\n",
       "      <td>0.201216</td>\n",
       "      <td>-0.067050</td>\n",
       "      <td>-0.178754</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.152394</td>\n",
       "      <td>-0.006992</td>\n",
       "      <td>0.112232</td>\n",
       "      <td>-0.198475</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.853472</td>\n",
       "      <td>-0.257058</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>-0.000296</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115677</th>\n",
       "      <td>73968.0</td>\n",
       "      <td>1.095432</td>\n",
       "      <td>-0.082201</td>\n",
       "      <td>0.557413</td>\n",
       "      <td>0.672936</td>\n",
       "      <td>-0.471535</td>\n",
       "      <td>-0.151216</td>\n",
       "      <td>-0.182268</td>\n",
       "      <td>0.145532</td>\n",
       "      <td>0.146361</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138275</td>\n",
       "      <td>-0.138794</td>\n",
       "      <td>-0.375464</td>\n",
       "      <td>0.083377</td>\n",
       "      <td>0.224129</td>\n",
       "      <td>0.211780</td>\n",
       "      <td>0.211859</td>\n",
       "      <td>-0.021616</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>28.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161391</th>\n",
       "      <td>114146.0</td>\n",
       "      <td>0.225211</td>\n",
       "      <td>-0.101200</td>\n",
       "      <td>0.597409</td>\n",
       "      <td>-1.261143</td>\n",
       "      <td>-0.482422</td>\n",
       "      <td>-0.508390</td>\n",
       "      <td>0.338604</td>\n",
       "      <td>-0.122385</td>\n",
       "      <td>-0.962887</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.402944</td>\n",
       "      <td>-0.242758</td>\n",
       "      <td>-0.249014</td>\n",
       "      <td>0.263371</td>\n",
       "      <td>1.144209</td>\n",
       "      <td>-0.580231</td>\n",
       "      <td>0.423566</td>\n",
       "      <td>-0.010651</td>\n",
       "      <td>0.016041</td>\n",
       "      <td>63.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270370</th>\n",
       "      <td>164044.0</td>\n",
       "      <td>-2.001444</td>\n",
       "      <td>-1.084340</td>\n",
       "      <td>0.042545</td>\n",
       "      <td>-1.061416</td>\n",
       "      <td>1.004215</td>\n",
       "      <td>2.054346</td>\n",
       "      <td>2.173900</td>\n",
       "      <td>0.347613</td>\n",
       "      <td>-0.991819</td>\n",
       "      <td>...</td>\n",
       "      <td>1.054444</td>\n",
       "      <td>0.699938</td>\n",
       "      <td>1.070446</td>\n",
       "      <td>0.585468</td>\n",
       "      <td>-0.922432</td>\n",
       "      <td>1.156154</td>\n",
       "      <td>0.683653</td>\n",
       "      <td>-0.197059</td>\n",
       "      <td>0.055466</td>\n",
       "      <td>492.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "228513  145544.0 -0.643139  0.323888 -0.253890 -0.229861 -0.320347 -0.337035   \n",
       "45271    42274.0  1.225032  0.309672  0.075764  1.172093  0.049135 -0.352607   \n",
       "115677   73968.0  1.095432 -0.082201  0.557413  0.672936 -0.471535 -0.151216   \n",
       "161391  114146.0  0.225211 -0.101200  0.597409 -1.261143 -0.482422 -0.508390   \n",
       "270370  164044.0 -2.001444 -1.084340  0.042545 -1.061416  1.004215  2.054346   \n",
       "\n",
       "              V7        V8        V9  ...       V20       V21       V22  \\\n",
       "228513  0.016371  0.511599  0.664531  ... -0.284546  0.264600  0.641559   \n",
       "45271   0.201216 -0.067050 -0.178754  ... -0.152394 -0.006992  0.112232   \n",
       "115677 -0.182268  0.145532  0.146361  ... -0.138275 -0.138794 -0.375464   \n",
       "161391  0.338604 -0.122385 -0.962887  ... -0.402944 -0.242758 -0.249014   \n",
       "270370  2.173900  0.347613 -0.991819  ...  1.054444  0.699938  1.070446   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \n",
       "228513  0.167731  0.639755 -0.782464  0.447755 -0.108167  0.041705  100.22  \n",
       "45271  -0.198475  0.012800  0.853472 -0.257058  0.005308 -0.000296    1.00  \n",
       "115677  0.083377  0.224129  0.211780  0.211859 -0.021616  0.005800   28.90  \n",
       "161391  0.263371  1.144209 -0.580231  0.423566 -0.010651  0.016041   63.00  \n",
       "270370  0.585468 -0.922432  1.156154  0.683653 -0.197059  0.055466  492.00  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "feature_names=data.columns.values[:-1]\n",
    "train_test_set = data[data.Class==0][feature_names]\n",
    "train_set, test_set = train_test_split(train_test_set, test_size=0.2, random_state=42)\n",
    "print('Whole data set:',len(data))\n",
    "print('Train and test set:',len(train_test_set))\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing with StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# scaler1=MinMaxScaler().fit(train_set[['Time']])\n",
    "# train_set['Time']=scaler1.transform(train_set[['Time']])\n",
    "# test_set['Time']=scaler1.transform(test_set[['Time']])\n",
    "# scaler2=StandardScaler().fit(train_set[['Amount']])\n",
    "# train_set['Amount']=scaler2.transform(train_set[['Amount']])\n",
    "# test_set['Amount']=scaler2.transform(test_set[['Amount']])\n",
    "\n",
    "# train_set.hist(column=['Time','Amount','V1','V2'],bins=100)\n",
    "# train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set=train_set.to_numpy()\n",
    "# test_set=test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing using MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.42327013e-01, 9.47367642e-01, 7.97217483e-01, 7.76227227e-01,\n",
       "        2.41740662e-01, 5.43571003e-01, 5.15661441e-01, 4.19171267e-01,\n",
       "        8.02040109e-01, 3.17799008e-01, 3.49988397e-01, 2.35464057e-01,\n",
       "        6.15377573e-01, 4.10107015e-01, 5.99855337e-01, 4.48405051e-01,\n",
       "        6.02247154e-01, 6.71423155e-01, 6.12703253e-01, 5.13449227e-01,\n",
       "        4.11165178e-01, 6.10928994e-01, 5.39959714e-01, 6.67924552e-01,\n",
       "        5.05950311e-01, 5.33984885e-01, 5.03033612e-01, 6.46853527e-01,\n",
       "        2.57966091e-01, 5.09856012e-03],\n",
       "       [2.44658194e-01, 9.79105547e-01, 7.97062325e-01, 7.83882282e-01,\n",
       "        3.03888114e-01, 5.48372609e-01, 5.15350500e-01, 4.21609233e-01,\n",
       "        7.95745386e-01, 2.79267731e-01, 3.87358807e-01, 3.75257082e-01,\n",
       "        6.96864586e-01, 5.41487510e-01, 6.50882451e-01, 3.64243237e-01,\n",
       "        5.45108394e-01, 6.30551391e-01, 5.31712561e-01, 5.85659779e-01,\n",
       "        4.13125001e-01, 6.06201154e-01, 5.15266633e-01, 6.62486089e-01,\n",
       "        4.14393519e-01, 6.25814080e-01, 3.86877333e-01, 6.50121975e-01,\n",
       "        2.57044176e-01, 5.08736791e-05],\n",
       "       [4.28085284e-01, 9.76903817e-01, 7.92785085e-01, 7.95066894e-01,\n",
       "        2.81760902e-01, 5.41606228e-01, 5.19372018e-01, 4.16551374e-01,\n",
       "        7.98057911e-01, 2.94122828e-01, 3.82722706e-01, 4.23409714e-01,\n",
       "        6.96713503e-01, 4.80975431e-01, 6.51095172e-01, 4.16707306e-01,\n",
       "        5.38879935e-01, 6.49554535e-01, 4.60419624e-01, 5.59412617e-01,\n",
       "        4.13334375e-01, 6.03906766e-01, 4.92515624e-01, 6.66671832e-01,\n",
       "        4.45254828e-01, 5.89794309e-01, 4.64156912e-01, 6.49346489e-01,\n",
       "        2.57177991e-01, 1.47024933e-03],\n",
       "       [6.60613006e-01, 9.62119830e-01, 7.92577715e-01, 7.95995661e-01,\n",
       "        1.96024775e-01, 5.41464749e-01, 5.12239717e-01, 4.23421281e-01,\n",
       "        7.95143427e-01, 2.43439220e-01, 3.86366982e-01, 2.65441977e-01,\n",
       "        6.61052720e-01, 6.31378917e-01, 6.24685427e-01, 3.99415698e-01,\n",
       "        4.72397221e-01, 6.41544966e-01, 6.07679144e-01, 4.68705164e-01,\n",
       "        4.09409317e-01, 6.02096978e-01, 4.98414514e-01, 6.69344894e-01,\n",
       "        5.79617828e-01, 5.45336710e-01, 4.99047106e-01, 6.49662296e-01,\n",
       "        2.57402782e-01, 3.20504179e-03],\n",
       "       [9.49394634e-01, 9.24291716e-01, 7.81846865e-01, 7.83110885e-01,\n",
       "        2.04878522e-01, 5.60784381e-01, 5.63414254e-01, 4.47627431e-01,\n",
       "        8.00256214e-01, 2.42117248e-01, 3.47658215e-01, 3.72141322e-01,\n",
       "        6.80310989e-01, 5.89587724e-01, 6.49526763e-01, 4.26456781e-01,\n",
       "        5.34933245e-01, 6.33813601e-01, 4.68956332e-01, 4.48415573e-01,\n",
       "        4.31022494e-01, 6.18507305e-01, 5.59967268e-01, 6.74128314e-01,\n",
       "        2.77817768e-01, 6.42804384e-01, 5.41910700e-01, 6.44293131e-01,\n",
       "        2.58268138e-01, 2.50298501e-02]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "scaler=MinMaxScaler().fit(train_set)\n",
    "train_set=scaler.transform(train_set)\n",
    "test_set=scaler.transform(test_set)\n",
    "\n",
    "pd.Series(train_set[:,0]).hist(bins=100)\n",
    "pd.Series(train_set[:,1]).hist(bins=100)\n",
    "pd.Series(train_set[:,2]).hist(bins=100)\n",
    "pd.Series(train_set[:,-1]).hist(bins=100)\n",
    "train_set[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self,num_input):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num_input, 15),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(15, 7))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(7, 15),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(15, num_input),\n",
    "            nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 300\n",
    "batch_size = 256\n",
    "lr = 0.01\n",
    "\n",
    "inputs = torch.tensor(train_set, dtype=torch.float32)\n",
    "dataset = TensorDataset(inputs)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-13 22:51:08.002994 epoch [5/300], loss:0.001127, test_set_loss:0.001151\n",
      "2020-04-13 22:51:14.496320 epoch [10/300], loss:0.001087, test_set_loss:0.001092\n",
      "2020-04-13 22:51:20.823426 epoch [15/300], loss:0.001082, test_set_loss:0.000939\n",
      "2020-04-13 22:51:26.860341 epoch [20/300], loss:0.000886, test_set_loss:0.000886\n",
      "2020-04-13 22:51:33.245403 epoch [25/300], loss:0.000885, test_set_loss:0.000903\n",
      "2020-04-13 22:51:40.312289 epoch [30/300], loss:0.000883, test_set_loss:0.000900\n",
      "2020-04-13 22:51:47.188794 epoch [35/300], loss:0.000882, test_set_loss:0.000886\n",
      "2020-04-13 22:51:54.762346 epoch [40/300], loss:0.000862, test_set_loss:0.000861\n",
      "2020-04-13 22:52:02.282541 epoch [45/300], loss:0.000856, test_set_loss:0.000849\n",
      "2020-04-13 22:52:09.819187 epoch [50/300], loss:0.000873, test_set_loss:0.000870\n",
      "2020-04-13 22:52:16.298288 epoch [55/300], loss:0.000852, test_set_loss:0.000843\n",
      "2020-04-13 22:52:23.228737 epoch [60/300], loss:0.000850, test_set_loss:0.000842\n",
      "2020-04-13 22:52:30.203175 epoch [65/300], loss:0.000849, test_set_loss:0.000841\n",
      "2020-04-13 22:52:37.973825 epoch [70/300], loss:0.000849, test_set_loss:0.000840\n",
      "2020-04-13 22:52:45.054863 epoch [75/300], loss:0.000848, test_set_loss:0.000842\n",
      "2020-04-13 22:52:52.698184 epoch [80/300], loss:0.000845, test_set_loss:0.000840\n",
      "2020-04-13 22:53:00.239843 epoch [85/300], loss:0.000848, test_set_loss:0.000841\n",
      "2020-04-13 22:53:08.368413 epoch [90/300], loss:0.000869, test_set_loss:0.000845\n",
      "2020-04-13 22:53:16.202564 epoch [95/300], loss:0.000847, test_set_loss:0.000842\n",
      "2020-04-13 22:53:23.852685 epoch [100/300], loss:0.001052, test_set_loss:0.001049\n",
      "2020-04-13 22:53:31.530362 epoch [105/300], loss:0.001040, test_set_loss:0.001054\n",
      "2020-04-13 22:53:38.458679 epoch [110/300], loss:0.001037, test_set_loss:0.001055\n",
      "2020-04-13 22:53:46.354038 epoch [115/300], loss:0.001771, test_set_loss:0.001633\n",
      "2020-04-13 22:53:53.643476 epoch [120/300], loss:0.001297, test_set_loss:0.001290\n",
      "2020-04-13 22:54:01.446578 epoch [125/300], loss:0.001268, test_set_loss:0.001263\n",
      "2020-04-13 22:54:08.568088 epoch [130/300], loss:0.001260, test_set_loss:0.001252\n",
      "2020-04-13 22:54:16.027666 epoch [135/300], loss:0.001259, test_set_loss:0.001252\n",
      "2020-04-13 22:54:23.875128 epoch [140/300], loss:0.001259, test_set_loss:0.001252\n",
      "2020-04-13 22:54:32.087923 epoch [145/300], loss:0.001251, test_set_loss:0.001246\n",
      "2020-04-13 22:54:39.847604 epoch [150/300], loss:0.004717, test_set_loss:0.004706\n",
      "2020-04-13 22:54:47.087060 epoch [155/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:54:54.951421 epoch [160/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:55:03.131139 epoch [165/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:55:11.288348 epoch [170/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:55:20.479227 epoch [175/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:55:29.701512 epoch [180/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:55:39.161057 epoch [185/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:55:47.858720 epoch [190/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:55:56.835499 epoch [195/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:56:05.859838 epoch [200/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:56:15.253090 epoch [205/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:56:24.641598 epoch [210/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:56:33.213649 epoch [215/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:56:41.769562 epoch [220/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:56:50.509121 epoch [225/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:57:00.323897 epoch [230/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:57:09.223238 epoch [235/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:57:18.029458 epoch [240/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:57:27.522880 epoch [245/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:57:37.559452 epoch [250/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:57:46.720770 epoch [255/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:57:55.430673 epoch [260/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:58:04.251916 epoch [265/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:58:13.954435 epoch [270/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:58:23.857970 epoch [275/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:58:32.859862 epoch [280/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:58:41.876527 epoch [285/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:58:50.405039 epoch [290/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:58:59.892185 epoch [295/300], loss:0.004715, test_set_loss:0.004706\n",
      "2020-04-13 22:59:09.394636 epoch [300/300], loss:0.004715, test_set_loss:0.004706\n"
     ]
    }
   ],
   "source": [
    "model = autoencoder(inputs.shape[1])\n",
    "model = model.cuda() if torch.cuda.is_available() else model\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if torch.cuda.is_available():\n",
    "            tests_=torch.tensor(test_set, dtype=torch.float32).cuda()\n",
    "        else:\n",
    "            tests_=torch.tensor(test_set, dtype=torch.float32)\n",
    "        outputs = model(tests_)\n",
    "        loss=criterion(outputs,tests_)\n",
    "    #print(tests_,outputs)\n",
    "    return loss.item()/(tests_.shape[0]*tests_.shape[1])\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    loss_sum=0.0; num=0\n",
    "    for inputs, in dataloader:\n",
    "        if torch.cuda.is_available():\n",
    "            inputs=inputs.cuda()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "\n",
    "        loss_sum+=loss.item()\n",
    "        num+=(inputs.shape[0]*inputs.shape[1])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1)%5 == 0:\n",
    "        print('{} epoch [{}/{}], loss:{:.6f}, test_set_loss:{:.6f}'\n",
    "                .format(datetime.now(), epoch + 1, num_epochs, loss_sum/num, test()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     test_set2 = data[data.Class==1][feature_names]\n",
    "#     test_set2['Time']=scaler1.transform(test_set2[['Time']])\n",
    "#     test_set2['Amount']=scaler2.transform(test_set2[['Amount']])\n",
    "#     inputs2=torch.tensor(test_set2.to_numpy(), dtype=torch.float32)\n",
    "#     outputs2=model(inputs2)\n",
    "#     loss2=torch.sum((inputs2-outputs2)**2,dim=1).sqrt().log()\n",
    "\n",
    "#     test_set1=test_set.sample(n=len(loss2),random_state=42)\n",
    "#     inputs1=torch.tensor(test_set1.to_numpy(), dtype=torch.float32)\n",
    "#     outputs1=model(inputs1)\n",
    "#     loss1=torch.sum((inputs1-outputs1)**2,dim=1).sqrt().log()\n",
    "\n",
    "#     pd.Series(loss1.numpy()).hist(bins=100)\n",
    "#     pd.Series(loss2.numpy()).hist(bins=100)\n",
    "#     split_point=(loss1.max()+loss2.min())/2\n",
    "#     print('Split point:',split_point)\n",
    "#     print((loss1<split_point).sum().item()/float(len(loss1)))\n",
    "#     print((loss2>split_point).sum().item()/float(len(loss2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split point: tensor(-0.9834)\n",
      "0.5853658536585366\n",
      "0.9207317073170732\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_set2 = data[data.Class==1][feature_names]\n",
    "    test_set2=scaler.transform(test_set2)\n",
    "    inputs2=torch.tensor(test_set2, dtype=torch.float32)\n",
    "    outputs2=model(inputs2)\n",
    "    loss2=torch.sum((inputs2-outputs2)**2,dim=1).sqrt().log()\n",
    "\n",
    "    test_set1=test_set[np.random.choice(len(test_set),size=len(loss2),replace=False)]\n",
    "    inputs1=torch.tensor(test_set1, dtype=torch.float32)\n",
    "    outputs1=model(inputs1)\n",
    "    loss1=torch.sum((inputs1-outputs1)**2,dim=1).sqrt().log()\n",
    "\n",
    "    pd.Series(loss1.numpy()).hist(bins=100)\n",
    "    pd.Series(loss2.numpy()).hist(bins=100)\n",
    "    split_point=(loss1.max()+loss2.min())/2\n",
    "    print('Split point:',split_point)\n",
    "    print((loss1<split_point).sum().item()/float(len(loss1)))\n",
    "    print((loss2>split_point).sum().item()/float(len(loss2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/Users/john/projects/cloudera-ml/anomaly-detection/creditcard-fraud-2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.4 64-bit ('miniconda3-latest': pyenv)",
   "language": "python",
   "name": "python36464bitminiconda3latestpyenvfaa952c22d91438a9b3b5ae49720d629"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
